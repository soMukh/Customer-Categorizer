{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c53ff9c",
   "metadata": {
    "id": "4c53ff9c"
   },
   "source": [
    "# Classification after Clustering with Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45ecb70",
   "metadata": {
    "id": "b45ecb70"
   },
   "source": [
    "### Import CSV and Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93a06238",
   "metadata": {
    "id": "93a06238",
    "outputId": "e60c0777-622a-4f97-b4da-c5c1a9d063f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2240, 22)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.pandas.set_option(\"display.max_columns\", None)\n",
    "# Create Dataframe\n",
    "df = pd.read_csv(r\"./data/clustered_data.csv\")\n",
    "# Print shape of dataset\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f6ca74",
   "metadata": {
    "id": "e0f6ca74"
   },
   "source": [
    "**Split X and y**\n",
    "- Why do we split our data?\n",
    "> Training Dataset is the part of Original Dataset that we use to train our ML model. The model learns on this data by running the algorithm and maps a function F(x) where “x” in the independent variable (inputs) for “y” where “y” is the dependent variable(output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1d3a48e",
   "metadata": {
    "id": "b1d3a48e"
   },
   "outputs": [],
   "source": [
    "X = df.drop(\"cluster\", axis=1) #dropping the target column which is 'cluster'\n",
    "y = df[\"cluster\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc221118",
   "metadata": {
    "id": "bc221118"
   },
   "source": [
    "## Grid Search\n",
    "\n",
    "- Why do we use Grid Search?\n",
    "\n",
    "`GridSearchCV` is a technique to search through the best parameter values from the given set of the grid of parameters. It is basically a cross-validation method. the model and the parameters are required to be fed in. Best parameter values are extracted and then the predictions are made."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4e23b9",
   "metadata": {},
   "source": [
    "## Select the best model\n",
    "- so here we have some list of the best classification algorithms we imported. Now we will compare each model's score and see which model is performing better than rest of the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7659f077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\etern\\anaconda3\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\etern\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\etern\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n",
      "Requirement already satisfied: catboost in c:\\users\\etern\\anaconda3\\lib\\site-packages (1.2.8)\n",
      "Requirement already satisfied: graphviz in c:\\users\\etern\\anaconda3\\lib\\site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\etern\\anaconda3\\lib\\site-packages (from catboost) (3.9.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in c:\\users\\etern\\anaconda3\\lib\\site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\etern\\anaconda3\\lib\\site-packages (from catboost) (2.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\etern\\anaconda3\\lib\\site-packages (from catboost) (1.13.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\etern\\anaconda3\\lib\\site-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in c:\\users\\etern\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\etern\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\etern\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\etern\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\etern\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\etern\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\etern\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\etern\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\etern\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\etern\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\etern\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.1.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\etern\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "!pip install catboost\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report,ConfusionMatrixDisplay,precision_score, recall_score, f1_score, roc_auc_score,roc_curve,confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn import metrics \n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "     \"K-Neighbors Classifier\": KNeighborsClassifier(),\n",
    "    \"XGBClassifier\": XGBClassifier(), \n",
    "     \"CatBoosting Classifier\": CatBoostClassifier(verbose=False),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0477f045",
   "metadata": {},
   "source": [
    "- ### We will create a generic function to check each model's performance so that we can compare those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2de9e39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function which can evaluate models and return a report \n",
    "def evaluate_models(X, y, models):\n",
    "    '''\n",
    "    This function takes in X and y and models dictionary as input\n",
    "    It splits the data into Train Test split\n",
    "    Iterates through the given model dictionary and evaluates the metrics\n",
    "    Returns: Dataframe which contains report of all models metrics with cost\n",
    "    '''\n",
    "    # separate dataset into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "    \n",
    "\n",
    "    models_list = []\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(len(list(models))):\n",
    "        model = list(models.values())[i]\n",
    "        model.fit(X_train, y_train) # Train model\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        score = accuracy_score(y_test,y_pred)\n",
    "        \n",
    "        model_name = list(models.keys())[i]\n",
    "        print(f'---- score for --- {model_name} ----')\n",
    "        print(f\"{score}\")\n",
    "        models_list.append(model_name)\n",
    "        scores.append(score)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    report = pd.DataFrame()\n",
    "    report['Model_name'] = models_list\n",
    "    report['Score'] = scores        \n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371050d9",
   "metadata": {},
   "source": [
    "### Let's check the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6eec8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- score for --- Random Forest ----\n",
      "0.96875\n",
      "---- score for --- Decision Tree ----\n",
      "0.9352678571428571\n",
      "---- score for --- Gradient Boosting ----\n",
      "0.9709821428571429\n",
      "---- score for --- Logistic Regression ----\n",
      "0.8794642857142857\n",
      "---- score for --- K-Neighbors Classifier ----\n",
      "0.8125\n",
      "---- score for --- XGBClassifier ----\n",
      "0.9665178571428571\n",
      "---- score for --- CatBoosting Classifier ----\n",
      "0.9776785714285714\n",
      "---- score for --- AdaBoost Classifier ----\n",
      "0.9375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = evaluate_models(X, y, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25c80379",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_name</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Neighbors Classifier</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.879464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.935268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.966518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.970982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoosting Classifier</td>\n",
       "      <td>0.977679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model_name     Score\n",
       "4  K-Neighbors Classifier  0.812500\n",
       "3     Logistic Regression  0.879464\n",
       "1           Decision Tree  0.935268\n",
       "7     AdaBoost Classifier  0.937500\n",
       "5           XGBClassifier  0.966518\n",
       "0           Random Forest  0.968750\n",
       "2       Gradient Boosting  0.970982\n",
       "6  CatBoosting Classifier  0.977679"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report.sort_values('Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63a7528",
   "metadata": {},
   "source": [
    "- ### From the report above we can see that the logistic regression model performed the best, so we will continue training our model using logistic regression algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73728d0",
   "metadata": {
    "id": "f73728d0"
   },
   "source": [
    "### Split into Train and test data\n",
    "\n",
    "- **Do you know why we split the train and test dataset?**\n",
    "> The train test split technique can be used for classification and regression problems to test machine learning algorithms. The procedure takes the given dataset and splits it into two subsets: ```Training data/train set:``` it is used to train the algorithm and fit the machine learning model\n",
    "then we have ```test data/test set``` which is basically a different data for which we know the values but this data was never shown to the model before. Thus if the model after training is performing good on test set as well then we can say that the Machine Learning model is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "130fe7f4",
   "metadata": {
    "id": "130fe7f4",
    "outputId": "4cced242-c7ca-40f1-d1c7-b229cd43ae35"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Parental Status</th>\n",
       "      <th>Children</th>\n",
       "      <th>Income</th>\n",
       "      <th>Total_Spending</th>\n",
       "      <th>Days_as_Customer</th>\n",
       "      <th>Recency</th>\n",
       "      <th>Wines</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Meat</th>\n",
       "      <th>Fish</th>\n",
       "      <th>Sweets</th>\n",
       "      <th>Gold</th>\n",
       "      <th>Web</th>\n",
       "      <th>Catalog</th>\n",
       "      <th>Store</th>\n",
       "      <th>Discount Purchases</th>\n",
       "      <th>Total Promo</th>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>64587.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>4034.0</td>\n",
       "      <td>49</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162</th>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47320.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>4359.0</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>19</td>\n",
       "      <td>111</td>\n",
       "      <td>50.0</td>\n",
       "      <td>15</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86429.0</td>\n",
       "      <td>1449.0</td>\n",
       "      <td>4247.0</td>\n",
       "      <td>10</td>\n",
       "      <td>464</td>\n",
       "      <td>28</td>\n",
       "      <td>556</td>\n",
       "      <td>29.0</td>\n",
       "      <td>18</td>\n",
       "      <td>37.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38593.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>4316.0</td>\n",
       "      <td>42</td>\n",
       "      <td>51</td>\n",
       "      <td>12</td>\n",
       "      <td>49</td>\n",
       "      <td>17.0</td>\n",
       "      <td>24</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72905.0</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>4186.0</td>\n",
       "      <td>52</td>\n",
       "      <td>407</td>\n",
       "      <td>81</td>\n",
       "      <td>445</td>\n",
       "      <td>120.5</td>\n",
       "      <td>81</td>\n",
       "      <td>126.5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44078.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4037.0</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>61825.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>4353.0</td>\n",
       "      <td>56</td>\n",
       "      <td>162</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>55.0</td>\n",
       "      <td>30</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>67381.0</td>\n",
       "      <td>957.0</td>\n",
       "      <td>4557.0</td>\n",
       "      <td>67</td>\n",
       "      <td>815</td>\n",
       "      <td>8</td>\n",
       "      <td>53</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>48918.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>4105.0</td>\n",
       "      <td>21</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23228.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4181.0</td>\n",
       "      <td>71</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1568 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Education  Marital Status  Parental Status  Children   Income  \\\n",
       "994    68          2               0                1         2  64587.0   \n",
       "2162   65          2               1                1         1  47320.0   \n",
       "906    61          2               0                0         0  86429.0   \n",
       "572    44          1               0                1         1  38593.0   \n",
       "1877   64          2               1                0         0  72905.0   \n",
       "...   ...        ...             ...              ...       ...      ...   \n",
       "1638   53          2               1                1         2  44078.0   \n",
       "1095   43          2               0                1         1  61825.0   \n",
       "1130   71          3               1                1         1  67381.0   \n",
       "1294   59          4               0                1         2  48918.0   \n",
       "860    53          2               1                1         1  23228.0   \n",
       "\n",
       "      Total_Spending  Days_as_Customer  Recency  Wines  Fruits  Meat   Fish  \\\n",
       "994            108.0            4034.0       49     66       0    16    0.0   \n",
       "2162           414.0            4359.0       10    200      19   111   50.0   \n",
       "906           1449.0            4247.0       10    464      28   556   29.0   \n",
       "572            177.0            4316.0       42     51      12    49   17.0   \n",
       "1877          1515.0            4186.0       52    407      81   445  120.5   \n",
       "...              ...               ...      ...    ...     ...   ...    ...   \n",
       "1638            41.0            4037.0       17     24       1    10    2.0   \n",
       "1095           424.0            4353.0       56    162      50   100   55.0   \n",
       "1130           957.0            4557.0       67    815       8    53   11.0   \n",
       "1294            62.0            4105.0       21     52       0     9    0.0   \n",
       "860             40.0            4181.0       71     13       2    18    6.0   \n",
       "\n",
       "      Sweets   Gold  Web  Catalog  Store  Discount Purchases  Total Promo  \\\n",
       "994        6   20.0    1        1      4                   2            0   \n",
       "2162      15   19.0    5        1      8                   6            0   \n",
       "906       18   37.0    7        4      7                   0            1   \n",
       "572       24   24.0    4        1      3                   3            0   \n",
       "1877      81  126.5    3        7      9                   1            1   \n",
       "...      ...    ...  ...      ...    ...                 ...          ...   \n",
       "1638       0    4.0    2        0      3                   2            0   \n",
       "1095      30   27.0    4        2      8                   1            0   \n",
       "1130       0   70.0    2        2      9                   4            1   \n",
       "1294       0    1.0    1        0      4                   2            0   \n",
       "860        1    0.0    2        0      3                   2            0   \n",
       "\n",
       "      NumWebVisitsMonth  \n",
       "994                   3  \n",
       "2162                  6  \n",
       "906                   2  \n",
       "572                   8  \n",
       "1877                  1  \n",
       "...                 ...  \n",
       "1638                  5  \n",
       "1095                  4  \n",
       "1130                  7  \n",
       "1294                  4  \n",
       "860                   8  \n",
       "\n",
       "[1568 rows x 21 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c42c967",
   "metadata": {},
   "source": [
    "### Let's do hyperparameter tuning\n",
    "- **And what's it actually?**\n",
    "\n",
    "> A Machine Learning model is defined as a mathematical model with a number of parameters that need to be learned from the data. By training a model with existing data, we are able to fit the model parameters. \n",
    "However, there is another kind of parameter, known as Hyperparameters, that cannot be directly learned from the regular training process. They are usually fixed before the actual training process begins. These parameters express important properties of the model such as its complexity or how fast it should learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3dd70ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 72 candidates, totalling 432 fits\n",
      "tuned hpyerparameters :(best parameters)  {'C': 100, 'max_iter': 100, 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "accuracy : 0.9712863034131788\n"
     ]
    }
   ],
   "source": [
    "# Grid search cross validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = [\n",
    "    {\n",
    "        'solver': ['liblinear'],                 # supports both l1 and l2\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'max_iter': [100, 200],\n",
    "        'multi_class': ['ovr']\n",
    "    },\n",
    "    {\n",
    "        'solver': ['lbfgs'],                     # only l2\n",
    "        'penalty': ['l2'],\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'max_iter': [100, 200],\n",
    "        'multi_class': ['ovr', 'multinomial']\n",
    "    },\n",
    "    {\n",
    "        'solver': ['saga'],                      # supports both\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': [0.01, 0.1, 1, 10],\n",
    "        'max_iter': [100, 200],\n",
    "        'multi_class': ['ovr', 'multinomial']\n",
    "    }\n",
    "]\n",
    "\n",
    "logreg=LogisticRegression()\n",
    "\n",
    "logreg_cv=GridSearchCV(logreg,params,cv=6,n_jobs=-1,verbose=1)\n",
    "logreg_cv.fit(X_train,y_train)\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "print(\"accuracy :\",logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beb2a8b",
   "metadata": {},
   "source": [
    "### So we got our best parameters. Let's now train the model with those parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2937ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr_model = LogisticRegression(\n",
    "    C = 100, \n",
    "    max_iter =  100,\n",
    "    multi_class =  'ovr', \n",
    "    penalty =  'l1', \n",
    "    solver =  'liblinear'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b132e02",
   "metadata": {
    "id": "8b132e02"
   },
   "source": [
    "**Initialize model with best parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17843664",
   "metadata": {
    "id": "17843664"
   },
   "source": [
    "### Let's check the report now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8fe3684",
   "metadata": {
    "id": "e8fe3684",
    "outputId": "67e7f682-eaff-4b97-de7c-706cf3af1797"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression\n",
      "Accuracy Score value: 0.9688\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       258\n",
      "           1       0.98      0.97      0.97       179\n",
      "           2       0.96      0.96      0.96       235\n",
      "\n",
      "    accuracy                           0.97       672\n",
      "   macro avg       0.97      0.97      0.97       672\n",
      "weighted avg       0.97      0.97      0.97       672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model = best_lr_model.fit(X_train,y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "score = accuracy_score(y_test,y_pred)\n",
    "cr = classification_report(y_test,y_pred)\n",
    "\n",
    "print(\"Logistic regression\")\n",
    "print (\"Accuracy Score value: {:.4f}\".format(score))\n",
    "print (cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf81d62",
   "metadata": {},
   "source": [
    "## Confusion matrix of the model\n",
    "- **What is confusion matrix ?**\n",
    "> The confusion matrix is a matrix used to determine the performance of the classification models for a given set of test data. It can only be determined if the true values for test data are known. The matrix itself can be easily understood, but the related terminologies may be confusing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78ddb30e",
   "metadata": {
    "id": "78ddb30e",
    "outputId": "4e62cc7f-7bed-4aa1-85aa-8df275d3750c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x23297ecf4a0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(best_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401046a4",
   "metadata": {},
   "source": [
    "- **Reports**\n",
    "\n",
    "**We can see, that the model performed pretty well.**\n",
    "- we have used logistic regression as it performed well than other models\n",
    "- We got a good accuracy while predicting the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fde78a4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
